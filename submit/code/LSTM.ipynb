{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueXwRsSKmmkc",
        "outputId": "b91fcfd5-9f18-40a1-adac-c003a0992c43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.11.0\n",
            "GPU detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import json\n",
        "import regex as re\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
        "np.random.seed(0)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import tensorflow as tf\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "print('GPU detected:', tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fHo4xrNCmu5O"
      },
      "outputs": [],
      "source": [
        "NUM_FEATURES = 8\n",
        "def word_shape_features(word):\n",
        "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
        "                     word.isdigit(),  word.isalpha(),word.isalnum(), word.isnumeric()])\n",
        "\n",
        "def get_word_features(word):\n",
        "    return word_shape_features(word)\n",
        "\n",
        "def get_sent_features(sent):\n",
        "    ret = []\n",
        "    for word in sent:\n",
        "        ret.append(get_word_features(word))\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v3N6pn1lneJm"
      },
      "outputs": [],
      "source": [
        "TAGS =  pickle.load(open( \"tags.pickle\", \"rb\" ))\n",
        "TAGS.remove(\"O\") \n",
        "NUM_TAGS = len(TAGS)\n",
        "# print(NUM_TAGS)\n",
        "\n",
        "tag2id = {}\n",
        "for id,label in enumerate(TAGS):\n",
        "    tag2id[label] = id \n",
        "\n",
        "def label2id(labels):\n",
        "    ret = []\n",
        "    prev_label = \"\"\n",
        "    for label in labels:\n",
        "        if label == \"O\":\n",
        "            ret.append([2*NUM_TAGS])\n",
        "        elif label == prev_label:\n",
        "            l =[tag2id[t]+ NUM_TAGS for t in label]\n",
        "            ret.append(l)\n",
        "        else:\n",
        "            l =[tag2id[t] for t in label]\n",
        "            ret.append(l)\n",
        "        prev_label = label\n",
        "    return ret "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "BjsBOtFbnxis"
      },
      "outputs": [],
      "source": [
        "def get_label(label_id):\n",
        "    if label_id == (2*NUM_TAGS):\n",
        "        return \"O\"\n",
        "    elif label_id >= NUM_TAGS:\n",
        "        return [TAGS[label_id-NUM_TAGS]]\n",
        "    else:\n",
        "        return TAGS[label_id]\n",
        "\n",
        "def id2label(labels):\n",
        "    ret = []\n",
        "    for label in labels:\n",
        "        l = [get_label(x) for x in label]\n",
        "        if len(l) == 1 and l[0] == \"O\":\n",
        "            l = \"O\"\n",
        "        ret.append(l)\n",
        "    return ret "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "lKfdMjXXn-81"
      },
      "outputs": [],
      "source": [
        "def clean_text(sent):\n",
        "    '''\n",
        "    This is text cleaning function\n",
        "    '''\n",
        "    ret_sent= []\n",
        "    for txt in sent:\n",
        "      fil_txt = re.sub('[^A-Za-z0-9]+', '', str(txt))\n",
        "      if len(fil_txt) == 0:\n",
        "        fil_txt  = txt [0]\n",
        "      ret_sent.append(fil_txt)\n",
        "    assert(len(ret_sent) == len(sent))\n",
        "    return ret_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BvqdHHZFoJ3z"
      },
      "outputs": [],
      "source": [
        "f = open('dev.json')\n",
        "data = json.load(f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z6_6mBLjogGo"
      },
      "outputs": [],
      "source": [
        "a = [d[\"sent\"] for d in data]\n",
        "set_ = set()\n",
        "for idx,s in enumerate(a):\n",
        "    for t in s:\n",
        "        if len(t)<1:\n",
        "            set_.add(idx)\n",
        "data = [data[i] for i in range(len(data)) if i not in set_]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GDcm5dM6o-H3"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data)\n",
        "data_cp = data.copy()\n",
        "df[\"sent\"] = df[\"sent\"].map( lambda x: clean_text(x))\n",
        "df[\"features\"] = df[\"sent\"].map(lambda x: get_sent_features(x))\n",
        "df[\"labels\"] = df[\"tags\"].map(lambda x: label2id(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOvWQfXhtCEX",
        "outputId": "3c519d4b-3477-40c1-e96b-d6f16c37a7d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 9,956\n"
          ]
        }
      ],
      "source": [
        "sentences = list(df[\"sent\"])\n",
        "labels = list(df[\"labels\"])\n",
        "unique_word_set = set()\n",
        "for x in sentences:\n",
        "  for w in x:\n",
        "    unique_word_set.add(w)\n",
        "words_to_id = {}\n",
        "for idx, w in enumerate(unique_word_set):\n",
        "  words_to_id[w] = idx\n",
        "\n",
        "num_words = len(unique_word_set)\n",
        "print(\"Number of training sentences: {:,}\".format(len(sentences)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LEioTz9u267o"
      },
      "outputs": [],
      "source": [
        "def to_bool_vec(y_id):\n",
        "    y_bool = np.zeros(2*NUM_TAGS+1, np.int32)\n",
        "    num_labels = len(y_id)\n",
        "    for id in y_id:\n",
        "        # for l in label:\n",
        "          y_bool[id] = 1\n",
        "    return y_bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIe06zF3pyOv",
        "outputId": "681726dd-1592-43ff-99fe-2a62b8904d21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(278, 50)\n",
            "float32\n",
            "(278, 50, 227)\n",
            "float32\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
        "\n",
        "max_len = 50\n",
        "\n",
        "X = np.array([np.array([words_to_id[w] for w in s], dtype=np.float32) for s in sentences])\n",
        "X = pad_sequences(maxlen=max_len, dtype='float32', sequences=X, padding=\"post\", value=(num_words-1))\n",
        "\n",
        "print(X.shape)\n",
        "print(X.dtype)\n",
        "\n",
        "y_padding = np.zeros(2*NUM_TAGS+1, np.float32)\n",
        "y_padding[2*NUM_TAGS] = 1.0\n",
        "\n",
        "y = np.array([np.array([to_bool_vec(lbl) for lbl in l], dtype=np.float32) for l in labels])\n",
        "y = pad_sequences(maxlen=max_len, dtype='float32', sequences=y, padding=\"post\", value=y_padding)\n",
        "\n",
        "print(y.shape)\n",
        "print(y.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OOA5nYaGqSXc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
        "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlnHfZVdtY-z",
        "outputId": "9467fea8-2181-4773-8e7d-faf100c07c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 50)]              0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 50, 50)            2109600   \n",
            "                                                                 \n",
            " spatial_dropout1d_2 (Spatia  (None, 50, 50)           0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 50, 226)          148256    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 50, 227)          51529     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,309,385\n",
            "Trainable params: 2,309,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(None, 50) <dtype: 'float32'>\n",
            "---------------\n",
            "(None, 50, 227) <dtype: 'float32'>\n",
            "---------------\n",
            "input_4 [(None, 50)] float32\n",
            "embedding_3 (None, 50) float32\n",
            "spatial_dropout1d_2 (None, 50, 50) float32\n",
            "bidirectional (None, 50, 50) float32\n",
            "time_distributed (None, 50, 226) float32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "input_word = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=num_words , output_dim=max_len, input_length=max_len)(input_word)\n",
        "model = SpatialDropout1D(0.1)(model)\n",
        "model = Bidirectional(LSTM(units=NUM_TAGS, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "out = TimeDistributed(Dense(2*NUM_TAGS+1, activation=\"softmax\"))(model)\n",
        "model = Model(input_word, out)\n",
        "model.summary()\n",
        "\n",
        "[print(i.shape, i.dtype) for i in model.inputs]\n",
        "print(\"---------------\")\n",
        "[print(o.shape, o.dtype) for o in model.outputs]\n",
        "print(\"---------------\")\n",
        "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Y4EW3JietcAr"
      },
      "outputs": [],
      "source": [
        "def multi_class_cross_entropy(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
        "    cross_entropy = -(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))\n",
        "    loss = K.sum(cross_entropy, axis=0)\n",
        "    return loss\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=multi_class_cross_entropy,\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr4k20GIty0I",
        "outputId": "cf9fc7b6-2b77-4584-bd59-f39ac2c3990d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "312/312 [==============================] - 145s 439ms/step - loss: 0.1649 - accuracy: 0.9530\n",
            "Epoch 2/3\n",
            "312/312 [==============================] - 120s 383ms/step - loss: 0.0967 - accuracy: 0.9582\n",
            "Epoch 3/3\n",
            "312/312 [==============================] - 114s 364ms/step - loss: 0.0861 - accuracy: 0.9576\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "chkpt = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=1, verbose=0, mode='max', baseline=None, restore_best_weights=False)\n",
        "\n",
        "history = model.fit(\n",
        "    x=X,\n",
        "    y=y,\n",
        "    batch_size=32, \n",
        "    epochs=3,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "GsS5PjwduEXn"
      },
      "outputs": [],
      "source": [
        "model.save_weights('./weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "fM3fMQZ045-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc548d2f-00db-43b3-9854-941e91430273"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of testing sentences: 278\n",
            "9/9 [==============================] - 0s 48ms/step - loss: 0.1741 - accuracy: 0.9194\n"
          ]
        }
      ],
      "source": [
        "f_test = open('test.json')\n",
        "data_test = json.load(f_test)\n",
        "f_test.close()\n",
        "\n",
        "a = [d[\"sent\"] for d in data_test]\n",
        "set_ = set()\n",
        "for idx,s in enumerate(a):\n",
        "    for t in s:\n",
        "        if len(t)<1:\n",
        "            set_.add(idx)\n",
        "\n",
        "data_test = [data_test[i] for i in range(len(data_test)) if i not in set_]\n",
        "df = pd.DataFrame(data_test)\n",
        "df[\"sent\"] = df[\"sent\"].map( lambda x: clean_text(x))\n",
        "df[\"features\"] = df[\"sent\"].map(lambda x: get_sent_features(x))\n",
        "df[\"labels\"] = df[\"tags\"].map(lambda x: label2id(x))\n",
        "\n",
        "sentences = list(df[\"sent\"])\n",
        "labels = list(df[\"labels\"])\n",
        "unique_word_set = set()\n",
        "for x in sentences:\n",
        "  for w in x:\n",
        "    unique_word_set.add(w)\n",
        "words_to_id = {}\n",
        "for idx, w in enumerate(unique_word_set):\n",
        "  words_to_id[w] = idx\n",
        "\n",
        "num_words = len(unique_word_set)\n",
        "print(\"Number of testing sentences: {:,}\".format(len(sentences)))\n",
        "\n",
        "X_test = np.array([np.array([words_to_id[w] for w in s], dtype=np.float32) for s in list(df[\"sent\"])])\n",
        "X_test = pad_sequences(maxlen=max_len, dtype='float32', sequences=X_test, padding=\"post\", value=(num_words-1))\n",
        "\n",
        "y_padding = np.zeros(2*NUM_TAGS+1, np.float32)\n",
        "y_padding[2*NUM_TAGS] = 1.0\n",
        "\n",
        "y_test = np.array([np.array([to_bool_vec(lbl) for lbl in l], dtype=np.float32) for l in list(df[\"labels\"])])\n",
        "y_test = pad_sequences(maxlen=max_len, dtype='float32', sequences=y_test, padding=\"post\", value=y_padding)\n",
        "\n",
        "out = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "byMTIXpZiqcH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}