{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueXwRsSKmmkc",
        "outputId": "6a552d1b-7a1b-4193-97f8-1b3ed7577051"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.11.0\n",
            "GPU detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import json\n",
        "import regex as re\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
        "np.random.seed(0)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import tensorflow as tf\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "print('GPU detected:', tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3kiZI5gXl1N",
        "outputId": "dc856946-bbcf-4d56-8011-830ceea4f59a"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "fHo4xrNCmu5O"
      },
      "outputs": [],
      "source": [
        "NUM_FEATURES = 8\n",
        "def word_shape_features(word):\n",
        "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
        "                     word.isdigit(),  word.isalpha(),word.isalnum(), word.isnumeric()])\n",
        "\n",
        "def get_word_features(word):\n",
        "    return word_shape_features(word)\n",
        "\n",
        "def get_sent_features(sent):\n",
        "    ret = []\n",
        "    for word in sent:\n",
        "        ret.append(get_word_features(word))\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "v3N6pn1lneJm"
      },
      "outputs": [],
      "source": [
        "TAGS =  pickle.load(open(\"tags.pickle\", \"rb\" ))\n",
        "TAGS.remove(\"O\") \n",
        "NUM_TAGS = len(TAGS)\n",
        "\n",
        "tag2id = {}\n",
        "for id,label in enumerate(TAGS):\n",
        "    tag2id[label] = id \n",
        "\n",
        "def label2id(labels):\n",
        "    ret = []\n",
        "    prev_label = \"\"\n",
        "    for label in labels:\n",
        "        if label == \"O\":\n",
        "            ret.append([2*NUM_TAGS])\n",
        "        elif label == prev_label:\n",
        "            l =[tag2id[t]+ NUM_TAGS for t in label]\n",
        "            ret.append(l)\n",
        "        else:\n",
        "            l =[tag2id[t] for t in label]\n",
        "            ret.append(l)\n",
        "        prev_label = label\n",
        "    return ret "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "BjsBOtFbnxis"
      },
      "outputs": [],
      "source": [
        "def get_label(label_id):\n",
        "    if label_id == (2*NUM_TAGS):\n",
        "        return \"O\"\n",
        "    elif label_id >= NUM_TAGS:\n",
        "        return [TAGS[label_id-NUM_TAGS]]\n",
        "    else:\n",
        "        return TAGS[label_id]\n",
        "\n",
        "def id2label(labels):\n",
        "    ret = []\n",
        "    for label in labels:\n",
        "        l = [get_label(x) for x in label]\n",
        "        if len(l) == 1 and l[0] == \"O\":\n",
        "            l = \"O\"\n",
        "        ret.append(l)\n",
        "    return ret "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "lKfdMjXXn-81"
      },
      "outputs": [],
      "source": [
        "def clean_text(sent):\n",
        "    '''\n",
        "    This is text cleaning function\n",
        "    '''\n",
        "    ret_sent= []\n",
        "    for txt in sent:\n",
        "      fil_txt = re.sub('[^A-Za-z0-9]+', '', str(txt))\n",
        "      if len(fil_txt) == 0:\n",
        "        fil_txt  = txt [0]\n",
        "      ret_sent.append(fil_txt)\n",
        "    assert(len(ret_sent) == len(sent))\n",
        "    return ret_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "BvqdHHZFoJ3z"
      },
      "outputs": [],
      "source": [
        "f = open('drive/MyDrive/train.json')\n",
        "data = json.load(f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "Z6_6mBLjogGo"
      },
      "outputs": [],
      "source": [
        "a = [d[\"sent\"] for d in data]\n",
        "set_ = set()\n",
        "for idx,s in enumerate(a):\n",
        "    for t in s:\n",
        "        if len(t)<1:\n",
        "            set_.add(idx)\n",
        "data = [data[i] for i in range(len(data)) if i not in set_]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce training size to fit in RAM\n",
        "print('Total Entries:', len(data))\n",
        "data = data[:500000]\n",
        "print('Reduced Entries:', len(data))"
      ],
      "metadata": {
        "id": "_73UOs5Tin31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "GDcm5dM6o-H3"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data)\n",
        "df[\"sent\"] = df[\"sent\"].map( lambda x: clean_text(x))\n",
        "df[\"features\"] = df[\"sent\"].map(lambda x: get_sent_features(x))\n",
        "df[\"labels\"] = df[\"tags\"].map(lambda x: label2id(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FOvWQfXhtCEX"
      },
      "outputs": [],
      "source": [
        "sentences = list(df[\"sent\"])\n",
        "labels = list(df[\"labels\"])\n",
        "unique_word_set = set()\n",
        "for x in sentences:\n",
        "  for w in x:\n",
        "    unique_word_set.add(w)\n",
        "words_to_id = {}\n",
        "for idx, w in enumerate(unique_word_set):\n",
        "  words_to_id[w] = idx\n",
        "\n",
        "num_words = len(unique_word_set)\n",
        "print(\"Number of training sentences: {:,}\".format(len(sentences)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "LEioTz9u267o"
      },
      "outputs": [],
      "source": [
        "def to_bool_vec(y_id):\n",
        "    y_bool = np.zeros(2*NUM_TAGS+1, np.int32)\n",
        "    num_labels = len(y_id)\n",
        "    for id in y_id:\n",
        "        # for l in label:\n",
        "          y_bool[id] = 1\n",
        "    return y_bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIe06zF3pyOv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
        "\n",
        "max_len = 105\n",
        "\n",
        "X = np.array([np.array([words_to_id[w] for w in s], dtype=np.float32) for s in sentences])\n",
        "X = pad_sequences(maxlen=max_len, dtype='float32', sequences=X, padding=\"post\", value=(num_words-1))\n",
        "\n",
        "print(X.shape)\n",
        "print(X.dtype)\n",
        "\n",
        "y_padding = np.zeros(2*NUM_TAGS+1, np.float32)\n",
        "y_padding[2*NUM_TAGS] = 1.0\n",
        "\n",
        "y = np.array([np.array([to_bool_vec(lbl) for lbl in l], dtype=np.float32) for l in labels])\n",
        "y = pad_sequences(maxlen=max_len, dtype='float32', sequences=y, padding=\"post\", value=y_padding)\n",
        "\n",
        "print(y.shape)\n",
        "print(y.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "OOA5nYaGqSXc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
        "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlnHfZVdtY-z",
        "outputId": "e5854e9b-b89c-4281-d77c-9d09bd5c1652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 105)]             0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 105, 105)          4430160   \n",
            "                                                                 \n",
            " spatial_dropout1d_2 (Spatia  (None, 105, 105)         0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 105, 226)         197976    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 105, 227)         51529     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,679,665\n",
            "Trainable params: 4,679,665\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(None, 105) <dtype: 'float32'>\n",
            "---------------\n",
            "(None, 105, 227) <dtype: 'float32'>\n",
            "---------------\n",
            "input_3 [(None, 105)] float32\n",
            "embedding_2 (None, 105) float32\n",
            "spatial_dropout1d_2 (None, 105, 105) float32\n",
            "bidirectional_2 (None, 105, 105) float32\n",
            "time_distributed_2 (None, 105, 226) float32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "input_word = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=num_words , output_dim=max_len, input_length=max_len)(input_word)\n",
        "model = SpatialDropout1D(0.1)(model)\n",
        "model = Bidirectional(LSTM(units=NUM_TAGS, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "out = TimeDistributed(Dense(2*NUM_TAGS+1, activation=\"softmax\"))(model)\n",
        "model = Model(input_word, out)\n",
        "model.summary()\n",
        "\n",
        "[print(i.shape, i.dtype) for i in model.inputs]\n",
        "print(\"---------------\")\n",
        "[print(o.shape, o.dtype) for o in model.outputs]\n",
        "print(\"---------------\")\n",
        "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Y4EW3JietcAr"
      },
      "outputs": [],
      "source": [
        "def multi_class_cross_entropy(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
        "    cross_entropy = -(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))\n",
        "    loss = K.sum(cross_entropy, axis=0)\n",
        "    return loss\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=multi_class_cross_entropy,\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dr4k20GIty0I"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "chkpt = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=1, verbose=0, mode='max', baseline=None, restore_best_weights=False)\n",
        "\n",
        "history = model.fit(\n",
        "    x=X,\n",
        "    y=y,\n",
        "    batch_size=32, \n",
        "    epochs=3,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "GsS5PjwduEXn"
      },
      "outputs": [],
      "source": [
        "model.save_weights('lstm_model')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_status = model.load_weights('lstm_model')\n",
        "load_status.assert_consumed()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08QNDsaZK1F8",
        "outputId": "b1d38d89-27c3-4ae0-947c-4fcf91184c19"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f543684cb80>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "fM3fMQZ045-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4a35f7d-0d43-4098-e30d-446cfe86d47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of testing sentences: 278\n",
            "9/9 [==============================] - 1s 64ms/step - loss: 0.0928 - accuracy: 0.9557\n"
          ]
        }
      ],
      "source": [
        "f_test = open('./drive/MyDrive/test.json')\n",
        "data_test = json.load(f_test)\n",
        "f_test.close()\n",
        "\n",
        "a = [d[\"sent\"] for d in data_test]\n",
        "set_ = set()\n",
        "for idx,s in enumerate(a):\n",
        "    for t in s:\n",
        "        if len(t)<1:\n",
        "            set_.add(idx)\n",
        "\n",
        "data_test = [data_test[i] for i in range(len(data_test)) if i not in set_]\n",
        "df = pd.DataFrame(data_test)\n",
        "df[\"sent\"] = df[\"sent\"].map( lambda x: clean_text(x))\n",
        "df[\"features\"] = df[\"sent\"].map(lambda x: get_sent_features(x))\n",
        "df[\"labels\"] = df[\"tags\"].map(lambda x: label2id(x))\n",
        "\n",
        "sentences = list(df[\"sent\"])\n",
        "labels = list(df[\"labels\"])\n",
        "unique_word_set = set()\n",
        "for x in sentences:\n",
        "  for w in x:\n",
        "    unique_word_set.add(w)\n",
        "words_to_id = {}\n",
        "for idx, w in enumerate(unique_word_set):\n",
        "  words_to_id[w] = idx\n",
        "\n",
        "num_words = len(unique_word_set)\n",
        "print(\"Number of testing sentences: {:,}\".format(len(sentences)))\n",
        "\n",
        "X_test = np.array([np.array([words_to_id[w] for w in s], dtype=np.float32) for s in list(df[\"sent\"])])\n",
        "X_test = pad_sequences(maxlen=max_len, dtype='float32', sequences=X_test, padding=\"post\", value=(num_words-1))\n",
        "\n",
        "y_padding = np.zeros(2*NUM_TAGS+1, np.float32)\n",
        "y_padding[2*NUM_TAGS] = 1.0\n",
        "\n",
        "y_test = np.array([np.array([to_bool_vec(lbl) for lbl in l], dtype=np.float32) for l in list(df[\"labels\"])])\n",
        "y_test = pad_sequences(maxlen=max_len, dtype='float32', sequences=y_test, padding=\"post\", value=y_padding)\n",
        "\n",
        "out = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "# predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "print(y_test.shape, y_pred.shape)"
      ],
      "metadata": {
        "id": "byMTIXpZiqcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab6c918e-fa61-4b7d-e8ed-9ec358cf27f6"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 1s 90ms/step\n",
            "(278, 105, 227) (278, 105, 227)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def f1(p, r):\n",
        "    if r == 0.:\n",
        "        return 0.\n",
        "    return 2 * p * r / float( p + r )\n",
        "\n",
        "def loose_macro(true, pred):\n",
        "    num_entities = len(true)\n",
        "    p = 0.\n",
        "    r = 0.\n",
        "    for true_labels, predicted_labels in zip(true, pred):\n",
        "        if len(predicted_labels) > 0:\n",
        "            p += len(set(predicted_labels).intersection(set(true_labels))) / float(len(predicted_labels))\n",
        "        if len(true_labels):\n",
        "            r += len(set(predicted_labels).intersection(set(true_labels))) / float(len(true_labels))\n",
        "    precision = p / num_entities\n",
        "    recall = r / num_entities\n",
        "    print('Precision:', precision)\n",
        "    print('Recall:', recall)\n",
        "    print('F1 Score:', f1( precision, recall))\n",
        "    return precision, recall, f1( precision, recall)\n",
        "\n",
        "def loose_micro(true, pred):\n",
        "    num_predicted_labels = 0.\n",
        "    num_true_labels = 0.\n",
        "    num_correct_labels = 0.\n",
        "    for true_labels, predicted_labels in zip(true, pred):\n",
        "        num_predicted_labels += len(predicted_labels)\n",
        "        num_true_labels += len(true_labels)\n",
        "        num_correct_labels += len(set(predicted_labels).intersection(set(true_labels))) \n",
        "    if num_predicted_labels > 0:\n",
        "        precision = num_correct_labels / num_predicted_labels\n",
        "    else:\n",
        "        precision = 0.\n",
        "    recall = num_correct_labels / num_true_labels\n",
        "    print('Precision:', precision)\n",
        "    print('Recall:', recall)\n",
        "    print('F1 Score:', f1( precision, recall))\n",
        "    return precision, recall, f1( precision, recall)"
      ],
      "metadata": {
        "id": "OR9cuQBkJkrP"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sum_mat = np.sum(y_test, axis=2)\n",
        "predicted_label_ids = y_pred [sum_mat > 0.1][:]\n",
        "all_true_labels = y_test [sum_mat > 0.1][:]\n",
        "\n",
        "xt = [i for i in range(all_true_labels.shape[0])if np.round(all_true_labels[i][226]) != 1]\n",
        "print(predicted_label_ids.shape, all_true_labels.shape)\n",
        "\n",
        "t = 0.7 #threshold\n",
        "pred = []\n",
        "true = []\n",
        "for p in predicted_label_ids:\n",
        "    rt = [i for (i,x) in enumerate(p) if x >t]\n",
        "    pred.append(rt)\n",
        "for p in all_true_labels:\n",
        "    rt = [i for (i,x) in enumerate(p) if round(x)  == 1]\n",
        "    true.append(rt)"
      ],
      "metadata": {
        "id": "ZrOVozW5puwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1eb299c-faf2-4816-d701-8e4cedb56509"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(29190, 227) (29190, 227)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Loose Macro Score')\n",
        "loose_macro(true,pred)\n",
        "print('-------------------------------')\n",
        "print('Loose Micro Score')\n",
        "loose_micro(true,pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx6fnhRVNjZC",
        "outputId": "407b6222-5369-4747-a16c-b871790c6b69"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loose Macro Score\n",
            "Precision: 0.8940047961630695\n",
            "Recall: 0.8940047961630695\n",
            "F1 Score: 0.8940047961630695\n",
            "-------------------------------\n",
            "Loose Micro Score\n",
            "Precision: 0.9700033453518195\n",
            "Recall: 0.8810263335584064\n",
            "F1 Score: 0.9233763246819879\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9700033453518195, 0.8810263335584064, 0.9233763246819879)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}