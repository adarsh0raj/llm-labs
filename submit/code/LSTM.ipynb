{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueXwRsSKmmkc",
        "outputId": "667d7ed1-b2c2-4fe3-d838-9529df7ff462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.11.0\n",
            "GPU detected: []\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import json\n",
        "import regex as re\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning) \n",
        "np.random.seed(0)\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "import tensorflow as tf\n",
        "print('Tensorflow version:', tf.__version__)\n",
        "print('GPU detected:', tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3kiZI5gXl1N",
        "outputId": "ed7807af-ceeb-41f3-8118-a810c572ff7d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fHo4xrNCmu5O"
      },
      "outputs": [],
      "source": [
        "NUM_FEATURES = 8\n",
        "def word_shape_features(word):\n",
        "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
        "                     word.isdigit(),  word.isalpha(),word.isalnum(), word.isnumeric()])\n",
        "\n",
        "def get_word_features(word):\n",
        "    return word_shape_features(word)\n",
        "\n",
        "def get_sent_features(sent):\n",
        "    ret = []\n",
        "    for word in sent:\n",
        "        ret.append(get_word_features(word))\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v3N6pn1lneJm"
      },
      "outputs": [],
      "source": [
        "TAGS =  pickle.load(open( \"tags.pickle\", \"rb\" ))\n",
        "TAGS.remove(\"O\") \n",
        "NUM_TAGS = len(TAGS)\n",
        "# print(NUM_TAGS)\n",
        "\n",
        "tag2id = {}\n",
        "for id,label in enumerate(TAGS):\n",
        "    tag2id[label] = id \n",
        "\n",
        "def label2id(labels):\n",
        "    ret = []\n",
        "    prev_label = \"\"\n",
        "    for label in labels:\n",
        "        if label == \"O\":\n",
        "            ret.append([2*NUM_TAGS])\n",
        "        elif label == prev_label:\n",
        "            l =[tag2id[t]+ NUM_TAGS for t in label]\n",
        "            ret.append(l)\n",
        "        else:\n",
        "            l =[tag2id[t] for t in label]\n",
        "            ret.append(l)\n",
        "        prev_label = label\n",
        "    return ret "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BjsBOtFbnxis"
      },
      "outputs": [],
      "source": [
        "def get_label(label_id):\n",
        "    if label_id == (2*NUM_TAGS):\n",
        "        return \"O\"\n",
        "    elif label_id >= NUM_TAGS:\n",
        "        return [TAGS[label_id-NUM_TAGS]]\n",
        "    else:\n",
        "        return TAGS[label_id]\n",
        "\n",
        "def id2label(labels):\n",
        "    ret = []\n",
        "    for label in labels:\n",
        "        l = [get_label(x) for x in label]\n",
        "        if len(l) == 1 and l[0] == \"O\":\n",
        "            l = \"O\"\n",
        "        ret.append(l)\n",
        "    return ret "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "lKfdMjXXn-81"
      },
      "outputs": [],
      "source": [
        "def clean_text(sent):\n",
        "    '''\n",
        "    This is text cleaning function\n",
        "    '''\n",
        "    ret_sent= []\n",
        "    for txt in sent:\n",
        "      fil_txt = re.sub('[^A-Za-z0-9]+', '', str(txt))\n",
        "      if len(fil_txt) == 0:\n",
        "        fil_txt  = txt [0]\n",
        "      ret_sent.append(fil_txt)\n",
        "    assert(len(ret_sent) == len(sent))\n",
        "    return ret_sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "BvqdHHZFoJ3z"
      },
      "outputs": [],
      "source": [
        "f = open('drive/MyDrive/train.json')\n",
        "data = json.load(f)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Z6_6mBLjogGo"
      },
      "outputs": [],
      "source": [
        "a = [d[\"sent\"] for d in data]\n",
        "set_ = set()\n",
        "for idx,s in enumerate(a):\n",
        "    for t in s:\n",
        "        if len(t)<1:\n",
        "            set_.add(idx)\n",
        "data = [data[i] for i in range(len(data)) if i not in set_]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce training size to fit in RAM\n",
        "print('Total Entries:', len(data))\n",
        "data = data[:20000]\n",
        "print('Reduced Entries:', len(data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_73UOs5Tin31",
        "outputId": "fa4d1cae-b26c-4f1f-ab88-71b33bcebaba"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Entries: 1247626\n",
            "Reduced Entries: 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GDcm5dM6o-H3"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data)\n",
        "df[\"sent\"] = df[\"sent\"].map( lambda x: clean_text(x))\n",
        "df[\"features\"] = df[\"sent\"].map(lambda x: get_sent_features(x))\n",
        "df[\"labels\"] = df[\"tags\"].map(lambda x: label2id(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOvWQfXhtCEX",
        "outputId": "5944c4a4-ff0b-4c96-e03c-834205f58b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 20,000\n"
          ]
        }
      ],
      "source": [
        "sentences = list(df[\"sent\"])\n",
        "labels = list(df[\"labels\"])\n",
        "unique_word_set = set()\n",
        "for x in sentences:\n",
        "  for w in x:\n",
        "    unique_word_set.add(w)\n",
        "words_to_id = {}\n",
        "for idx, w in enumerate(unique_word_set):\n",
        "  words_to_id[w] = idx\n",
        "\n",
        "num_words = len(unique_word_set)\n",
        "print(\"Number of training sentences: {:,}\".format(len(sentences)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LEioTz9u267o"
      },
      "outputs": [],
      "source": [
        "def to_bool_vec(y_id):\n",
        "    y_bool = np.zeros(2*NUM_TAGS+1, np.int32)\n",
        "    num_labels = len(y_id)\n",
        "    for id in y_id:\n",
        "        # for l in label:\n",
        "          y_bool[id] = 1\n",
        "    return y_bool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIe06zF3pyOv",
        "outputId": "517f26c6-5adc-4ddd-e42d-d990e1618867"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 105)\n",
            "float32\n",
            "(20000, 105, 227)\n",
            "float32\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.utils import pad_sequences, to_categorical\n",
        "\n",
        "max_len = 105\n",
        "\n",
        "X = np.array([np.array([words_to_id[w] for w in s], dtype=np.float32) for s in sentences])\n",
        "X = pad_sequences(maxlen=max_len, dtype='float32', sequences=X, padding=\"post\", value=(num_words-1))\n",
        "\n",
        "print(X.shape)\n",
        "print(X.dtype)\n",
        "\n",
        "y_padding = np.zeros(2*NUM_TAGS+1, np.float32)\n",
        "y_padding[2*NUM_TAGS] = 1.0\n",
        "\n",
        "y = np.array([np.array([to_bool_vec(lbl) for lbl in l], dtype=np.float32) for l in labels])\n",
        "y = pad_sequences(maxlen=max_len, dtype='float32', sequences=y, padding=\"post\", value=y_padding)\n",
        "\n",
        "print(y.shape)\n",
        "print(y.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "OOA5nYaGqSXc"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
        "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlnHfZVdtY-z",
        "outputId": "af6bfc03-f956-47ad-92d1-5db091041dd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 105)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 105, 105)          6989115   \n",
            "                                                                 \n",
            " spatial_dropout1d (SpatialD  (None, 105, 105)         0         \n",
            " ropout1D)                                                       \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 105, 226)         197976    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 105, 227)         51529     \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,238,620\n",
            "Trainable params: 7,238,620\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(None, 105) <dtype: 'float32'>\n",
            "---------------\n",
            "(None, 105, 227) <dtype: 'float32'>\n",
            "---------------\n",
            "input_1 [(None, 105)] float32\n",
            "embedding (None, 105) float32\n",
            "spatial_dropout1d (None, 105, 105) float32\n",
            "bidirectional (None, 105, 105) float32\n",
            "time_distributed (None, 105, 226) float32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[None, None, None, None, None]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "input_word = Input(shape=(max_len,))\n",
        "model = Embedding(input_dim=num_words , output_dim=max_len, input_length=max_len)(input_word)\n",
        "model = SpatialDropout1D(0.1)(model)\n",
        "model = Bidirectional(LSTM(units=NUM_TAGS, return_sequences=True, recurrent_dropout=0.1))(model)\n",
        "out = TimeDistributed(Dense(2*NUM_TAGS+1, activation=\"softmax\"))(model)\n",
        "model = Model(input_word, out)\n",
        "model.summary()\n",
        "\n",
        "[print(i.shape, i.dtype) for i in model.inputs]\n",
        "print(\"---------------\")\n",
        "[print(o.shape, o.dtype) for o in model.outputs]\n",
        "print(\"---------------\")\n",
        "[print(l.name, l.input_shape, l.dtype) for l in model.layers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Y4EW3JietcAr"
      },
      "outputs": [],
      "source": [
        "def multi_class_cross_entropy(y_true, y_pred):\n",
        "    y_true = K.cast(y_true, 'float32')\n",
        "    y_pred = K.cast(y_pred, 'float32')\n",
        "    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n",
        "    cross_entropy = -(y_true * K.log(y_pred) + (1 - y_true) * K.log(1 - y_pred))\n",
        "    loss = K.sum(cross_entropy, axis=0)\n",
        "    return loss\n",
        "\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=multi_class_cross_entropy,\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dr4k20GIty0I",
        "outputId": "14b13abe-90bd-4798-9df7-98bb77b429c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 447s 707ms/step - loss: 0.1097 - accuracy: 0.9560\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 427s 684ms/step - loss: 0.0733 - accuracy: 0.9548\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 427s 683ms/step - loss: 0.0633 - accuracy: 0.9549\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "chkpt = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=1, verbose=0, mode='max', baseline=None, restore_best_weights=False)\n",
        "\n",
        "history = model.fit(\n",
        "    x=X,\n",
        "    y=y,\n",
        "    batch_size=32, \n",
        "    epochs=3,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GsS5PjwduEXn"
      },
      "outputs": [],
      "source": [
        "model.save('lstm_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "fM3fMQZ045-q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9666cf6e-203f-433d-c798-b179da3049a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of testing sentences: 278\n",
            "9/9 [==============================] - 2s 109ms/step - loss: 0.0811 - accuracy: 0.9664\n"
          ]
        }
      ],
      "source": [
        "f_test = open('./drive/MyDrive/test.json')\n",
        "data_test = json.load(f_test)\n",
        "f_test.close()\n",
        "\n",
        "a = [d[\"sent\"] for d in data_test]\n",
        "set_ = set()\n",
        "for idx,s in enumerate(a):\n",
        "    for t in s:\n",
        "        if len(t)<1:\n",
        "            set_.add(idx)\n",
        "\n",
        "data_test = [data_test[i] for i in range(len(data_test)) if i not in set_]\n",
        "df = pd.DataFrame(data_test)\n",
        "df[\"sent\"] = df[\"sent\"].map( lambda x: clean_text(x))\n",
        "df[\"features\"] = df[\"sent\"].map(lambda x: get_sent_features(x))\n",
        "df[\"labels\"] = df[\"tags\"].map(lambda x: label2id(x))\n",
        "\n",
        "sentences = list(df[\"sent\"])\n",
        "labels = list(df[\"labels\"])\n",
        "unique_word_set = set()\n",
        "for x in sentences:\n",
        "  for w in x:\n",
        "    unique_word_set.add(w)\n",
        "words_to_id = {}\n",
        "for idx, w in enumerate(unique_word_set):\n",
        "  words_to_id[w] = idx\n",
        "\n",
        "num_words = len(unique_word_set)\n",
        "print(\"Number of testing sentences: {:,}\".format(len(sentences)))\n",
        "\n",
        "X_test = np.array([np.array([words_to_id[w] for w in s], dtype=np.float32) for s in list(df[\"sent\"])])\n",
        "X_test = pad_sequences(maxlen=max_len, dtype='float32', sequences=X_test, padding=\"post\", value=(num_words-1))\n",
        "\n",
        "y_padding = np.zeros(2*NUM_TAGS+1, np.float32)\n",
        "y_padding[2*NUM_TAGS] = 1.0\n",
        "\n",
        "y_test = np.array([np.array([to_bool_vec(lbl) for lbl in l], dtype=np.float32) for l in list(df[\"labels\"])])\n",
        "y_test = pad_sequences(maxlen=max_len, dtype='float32', sequences=y_test, padding=\"post\", value=y_padding)\n",
        "\n",
        "out = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "# predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#TODO\n",
        "\n",
        "print(X_test[0][5])\n",
        "print(y_test[0][5])\n",
        "print(y_pred[0][5])\n",
        "\n",
        "# calculate precision, recall, and f1 score\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# print the results\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 score:\", f1)"
      ],
      "metadata": {
        "id": "byMTIXpZiqcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZrOVozW5puwl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}