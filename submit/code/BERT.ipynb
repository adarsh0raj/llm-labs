{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EQ9r110W16eF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "import wget\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGmxlfMj2O-h",
    "outputId": "523754a0-8e91-4b4e-a77b-ea4831e776f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Available: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print( torch.cuda.device_count())\n",
    "    print('Available:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JF22X4Ak2Re6",
    "outputId": "d20f0e25-80d3-4389-e7e3-20fea38b7ef3"
   },
   "outputs": [],
   "source": [
    "!pip install wget\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5GCuBeo2UaV"
   },
   "outputs": [],
   "source": [
    "# url_data = ''\n",
    "# wget.download(url_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "55ebZib03nxy"
   },
   "outputs": [],
   "source": [
    "def word_shape_features(word):\n",
    "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
    "                     word.isdigit(),  word.isalpha(),word.isalnum(), word.isnumeric()])\n",
    "\n",
    "def get_word_features(word):\n",
    "    return word_shape_features(word)\n",
    "\n",
    "def get_sent_features(sent):\n",
    "    ret = []\n",
    "    for word in sent:\n",
    "        ret.append(get_word_features(word))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yWfSqa2v3w7r"
   },
   "outputs": [],
   "source": [
    "TAGS =  pickle.load(open( \"tags.pickle\", \"rb\" ))\n",
    "TAGS.remove(\"O\") \n",
    "NUM_TAGS = len(TAGS)\n",
    "\n",
    "tag2id = {}\n",
    "for id,label in enumerate(TAGS):\n",
    "    tag2id[label] = id \n",
    "\n",
    "def label2id(labels):\n",
    "    ret = []\n",
    "    prev_label = \"\"\n",
    "    for label in labels:\n",
    "        if label == \"O\":\n",
    "            ret.append([2*NUM_TAGS])\n",
    "        elif label == prev_label:\n",
    "            l =[tag2id[t]+ NUM_TAGS for t in label]\n",
    "            ret.append(l)\n",
    "        else:\n",
    "            l =[tag2id[t] for t in label]\n",
    "            ret.append(l)\n",
    "        prev_label = label\n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tixMcZNi3uOb"
   },
   "outputs": [],
   "source": [
    "def get_label(label_id):\n",
    "    if label_id == (2*NUM_TAGS):\n",
    "        return \"O\"\n",
    "    elif label_id >= NUM_TAGS:\n",
    "        return [TAGS[label_id-NUM_TAGS]]\n",
    "    else:\n",
    "        return TAGS[label_id]\n",
    "\n",
    "def id2label(labels):\n",
    "    ret = []\n",
    "    for label in labels:\n",
    "        l = [get_label(x) for x in label]\n",
    "        if len(l) == 1 and l[0] == \"O\":\n",
    "            l = \"O\"\n",
    "        ret.append(l)\n",
    "    return ret \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "V5ECkv6eL9RI"
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "def clean_text(sent):\n",
    "    '''\n",
    "    This is text cleaning function\n",
    "    '''\n",
    "    ret_sent= []\n",
    "    for txt in sent:\n",
    "#       if len(txt) < 1:\n",
    "# #         print(\"HI\",txt, sent)\n",
    "#         return -1\n",
    "      fil_txt = re.sub('[^A-Za-z0-9]+', '', str(txt))\n",
    "      if len(fil_txt) == 0:\n",
    "        fil_txt  = txt [0]\n",
    "      ret_sent.append(fil_txt)\n",
    "    assert(len(ret_sent) == len(sent))\n",
    "    return ret_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lFbrUUGL6gJ",
    "outputId": "446ccad2-a59a-47cb-b88d-ca39ab9b43be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABC', '-']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text([\"---ABC\", \"--\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "iXheFtu53rhq"
   },
   "outputs": [],
   "source": [
    "f = open('data/train.json')\n",
    "data = json.load(f)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [d[\"sent\"] for d in data]\n",
    "set_ = set()\n",
    "for idx,s in enumerate(a):\n",
    "    for t in s:\n",
    "        if len(t)<1:\n",
    "            set_.add(idx)\n",
    "data = [data[i] for i in range(len(data)) if i not in set_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cp =data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df [:2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data_cp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sent\"] = df[\"sent\"].map( lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"features\"] = df[\"sent\"].map(lambda x: get_sent_features(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"labels\"] = df[\"tags\"].map(lambda x: label2id(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('processed_dataframe', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(df, file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for id, d in enumerate(data):\n",
    "#     data[id][\"sent\"] = clean_text(data[id][\"sent\"])\n",
    "# for id, d in enumerate(data):\n",
    "#     data[id][\"features\"] = get_sent_features(d[\"sent\"])\n",
    "#     data[id][\"labels\"] = label2id(d[\"tags\"])\n",
    "    \n",
    "    # import pandas as pd\n",
    "# df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "ngqoBotS4eSM",
    "outputId": "3a1c234c-48ca-4267-d713-a065e77eb4f2"
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141,
     "referenced_widgets": [
      "b233bf4bab374f2896ce104d99f13827",
      "237c7cfb3d444ae7984bbd8ea533106f",
      "fdc50b855ddb494b9765751101814c40",
      "45aaad9a51434af588ea9b8d8d68bb05",
      "400ee20667f94c7aac1574be3a1a9e5e",
      "54903b3d0a9246ffb22a2a98d0efb44c",
      "6700cf33f9f54ac98ec1f8372a7864d3",
      "e02aec09e217439e8d4bd886dbcb277f",
      "a33c6625ca5c40ed94757906d8336113",
      "4ee46924befa45ed9d5478edde21495b",
      "75b50857bb224e7cb8b97d4526adf383",
      "e935a869ed12455fb576203015cec180",
      "54659ba43744406ca9d84e0a8436e4a6",
      "bcc6be30fffb45399b37a7f6692b08ee",
      "575152d3234a481e9d1497562517db92",
      "01b14a65e71d426091b7c30555780b6b",
      "f38d803a38eb4aeba24d4934a293b683",
      "ebaf2717cd204b24a53854b272f8ee4b",
      "3edaa70eaede4b6fb0480e3ca79b39fd",
      "ff7ec28470d24e2db9ba2da9212940d6",
      "5a1d1c7a34074d4b9ac1002ce35eaed2",
      "1c9f7c3885d84bc0adcb0fe5e1f6fa09",
      "c447f434facb4e7dad6d68cdb7d3c9ed",
      "43f47bad9a884045af5adee529af47ac",
      "0f680bcfe2424abbb433b4f4f7c200bf",
      "ecee498b70ac4f74ae130814f34681d2",
      "31ea48f16f46494ca5873eecbc164a71",
      "02d44ec9f6c84507bbbfd53b506ace62",
      "a3ef234e82dc43eda9be0529defef357",
      "5cd01d46aceb47fa85c71a36d8ffd9e6",
      "87596d96a965425a83870c1e0ff759ae",
      "5608b9e6a55142628a844b0766d3553f",
      "21e8758e69b641759a450407231f8db5"
     ]
    },
    "id": "MSVMBUOd3ZFp",
    "outputId": "9a49eead-8bc5-4b3d-b08b-ad4aac326e1d"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "waHHoaZR45_e",
    "outputId": "43f75b99-4148-4146-c3c2-9a8c2f248ff9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] show me films with drew [UNK] from the 1980s [SEP]'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([101, 2265, 2033, 3152, 2007, 3881, 100, 2013, 1996, 3865, 102])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RlsrV6YD5CCf"
   },
   "outputs": [],
   "source": [
    "sentences = list(df[\"sent\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nVOs5sXB-lX3"
   },
   "outputs": [],
   "source": [
    "labels = list(df[\"labels\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "SoebagJF5RMI",
    "outputId": "d4a69be4-b1d5-4c91-d078-282d4c97f5e0"
   },
   "outputs": [],
   "source": [
    "' '.join(sentences[34])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCUQTaMz5YH0",
    "outputId": "1fb50f55-4748-4686-ca68-2c65e3eef43a"
   },
   "outputs": [],
   "source": [
    "print(\"Number of training sentences: {:,}\".format(len(sentences)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfW4UOPT5azU"
   },
   "outputs": [],
   "source": [
    "# TokenLength=[len(tokenizer.encode(' '.join(i),add_special_tokens=True)) for i in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "mt = []\n",
    "for i in tqdm(sentences):\n",
    "    mt.append(len(tokenizer.encode(' '.join(i),add_special_tokens=True)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TokenLength = [x for x in mt if x >100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_retain = [i for i,x in enumerate(mt) if x <103]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [ sentences[i] for i in to_retain]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels =  [ labels[i] for i in to_retain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mt), len(TokenLength), len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DaWANyir5gFG",
    "outputId": "75de73c7-896f-4bc0-a098-2b38a8859761"
   },
   "outputs": [],
   "source": [
    "print('Minimum  length: {:,} tokens'.format(min(TokenLength)))\n",
    "print('Maximum length: {:,} tokens'.format(max(TokenLength)))\n",
    "print('Median length: {:,} tokens'.format(int(np.median(TokenLength))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.figure(figsize=(24,24))\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "\n",
    "# Plot the distribution of comment lengths.\n",
    "sns.distplot(TokenLength, kde=False, rug=False,color='plum')\n",
    "\n",
    "plt.title('Sentence Lengths')\n",
    "plt.xlabel('Sentence Length')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YpQNZOKt5qmD",
    "outputId": "9fc5ddf6-6e54-4c3b-94a6-13b4cedf9dc4"
   },
   "outputs": [],
   "source": [
    "SampleSentence=tokenizer.encode_plus(\"- abc\", add_special_tokens = True,truncation = True,max_length = 100,padding = True,return_attention_mask = True, return_tensors = 'pt')\n",
    "SampleSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "LzDpZzGLKvaU",
    "outputId": "16e08f0a-c3e0-45e3-f2b1-817b8a20c248"
   },
   "outputs": [],
   "source": [
    "tokenizer.ids_to_tokens[1011]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yG2ssTVE50J0",
    "outputId": "0ebab2ea-dda2-4f8b-e37f-bdba61e58680"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2500/2500 [00:01<00:00, 1375.30it/s]\n"
     ]
    }
   ],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in tqdm(sentences):\n",
    "\n",
    "    sent_str = ' '.join(sent)\n",
    "#     print(len(sent))\n",
    "#     print(sent_str)\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent_str,                 \n",
    "                        add_special_tokens = False,\n",
    "                        truncation = True,\n",
    "                        max_length = 105,           \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   \n",
    "                        return_tensors = 'pt',     \n",
    "                   )\n",
    "    \n",
    "        \n",
    "    input_ids.append(encoded_dict['input_ids'][0])\n",
    "    \n",
    "    # And its attention mask\n",
    "    attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "    # break\n",
    "\n",
    "# print('Original: ', sentences[24])\n",
    "# print('Token IDs:', input_ids[24])\n",
    "# print('Masks:', attention_masks[24])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i11 = input_ids.copy()\n",
    "i12 = attention_masks.copy()\n",
    "i13= labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = input_ids[:2000]\n",
    "attention_masks = attention_masks[:2000]\n",
    "labels = labels[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "eoX1GeW4TXh8"
   },
   "outputs": [],
   "source": [
    "def to_bool_vec(y_id):\n",
    "    y_bool = np.zeros(2*NUM_TAGS+1, np.int32)\n",
    "    num_labels = len(y_id)\n",
    "    for id in y_id:\n",
    "        # for l in label:\n",
    "          y_bool[id] = 1\n",
    "    return y_bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "N7Lc2Xiz6OTZ"
   },
   "outputs": [],
   "source": [
    "new_labels = []\n",
    "\n",
    "# The special label ID we'll give to \"extra\" tokens.\n",
    "to_remove_idx = []\n",
    "null_label_id =  np.zeros(2*NUM_TAGS+1, np.int32) #-100\n",
    "idx = 0\n",
    "for (tokens, masks, orig_labels) in zip(input_ids, attention_masks, labels):\n",
    "    \n",
    "    padded_labels = []\n",
    "    ty = 0\n",
    "    orig_labels_i = 0 \n",
    "    # print(tokens, masks, orig_labels)\n",
    "\n",
    "    for token_id,mask_id in zip(tokens,masks):\n",
    "      token_id = token_id.numpy().item()\n",
    "\n",
    "      if mask_id.numpy().item() == 0:\n",
    "        padded_labels.append(null_label_id)\n",
    "      \n",
    "\n",
    "      elif (token_id == tokenizer.pad_token_id) or \\\n",
    "          (token_id == tokenizer.cls_token_id) or \\\n",
    "          (token_id == tokenizer.sep_token_id):\n",
    "          \n",
    "          padded_labels.append(null_label_id)\n",
    "\n",
    "      elif tokenizer.ids_to_tokens[token_id][0:2] == '##':\n",
    "\n",
    "          padded_labels.append(null_label_id)\n",
    " \n",
    "      else:\n",
    "        # print(tokenizer.ids_to_tokens[token_id], orig_labels_i, len(orig_labels))\n",
    "        if orig_labels_i >= len(orig_labels):\n",
    "          ty+=1\n",
    "          break\n",
    "        else:\n",
    "          \n",
    "          padded_labels.append(to_bool_vec(orig_labels[orig_labels_i]))\n",
    "        orig_labels_i += 1\n",
    "\n",
    "    # assert(len(sen) == len(padded_labels))    \n",
    "    if ty == 0:\n",
    "      new_labels.append(padded_labels)\n",
    "    else:\n",
    "      to_remove_idx.append(idx)\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OgU9fIE8GOIy",
    "outputId": "63f23e47-23c1-4ac9-c966-34f93bff90ee"
   },
   "outputs": [],
   "source": [
    "print(ty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeIg71FHHc5z"
   },
   "outputs": [],
   "source": [
    "filtered_attention_masks = [attention_masks[idx] for idx in range(len(attention_masks)) if idx not in to_remove_idx]\n",
    "filtered_input_ids = [input_ids[idx] for idx in range(len(input_ids)) if idx not in to_remove_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCmE9pb9IERl",
    "outputId": "70428ba2-913f-4ee8-820b-d9c7062eb824"
   },
   "outputs": [],
   "source": [
    "len(input_ids), len(to_remove_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XxqRPfeE964V"
   },
   "outputs": [],
   "source": [
    "pt_input_ids = torch.stack(filtered_input_ids, dim=0)\n",
    "\n",
    "pt_attention_masks = torch.stack(filtered_attention_masks, dim=0)\n",
    "\n",
    "pt_labels = torch.tensor(new_labels, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZTWItCJ6OMFq"
   },
   "outputs": [],
   "source": [
    "# for x in pt_labels:\n",
    "#   for y in x:\n",
    "#     if torch.sum(y) == 0:\n",
    "#       print(y)  \n",
    "#       break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgMwJX-e-Avq",
    "outputId": "87fb084a-ac3d-4dee-cab1-d4e6f243ab22"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "train_dataset = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "\n",
    "print('{:>5,} training samples'.format(len(train_dataset)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rotmXu0x97xr",
    "outputId": "4a565314-6242-40f5-b19a-385e78b86159"
   },
   "outputs": [],
   "source": [
    "print('\\nSentence:    ', sentences[2])\n",
    "print('\\nLabels:      ', labels[2])\n",
    "print('\\nBERT Tokens: ', tokenizer.tokenize(' '.join(sentences[2])))\n",
    "print('\\nToken IDs:   ', input_ids[2])\n",
    "print('\\nNew Labels:  ', new_labels[2])\n",
    "print('\\nMask:        ', attention_masks[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iE_Cw3-C57k3"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, sampler = RandomSampler(train_dataset), batch_size = batch_size )\n",
    "\n",
    "# validation_dataloader = DataLoader(val_dataset, sampler = SequentialSampler(val_dataset), batch_size = batch_size   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJax2Fuu6WuP",
    "outputId": "bfd86522-17e4-4107-c0d4-7b85d678db80"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification, AdamW, BertConfig\n",
    "\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels = len(TAGS)*2 + 1, output_attentions = False, output_hidden_states = False)\n",
    "\n",
    "\n",
    "# model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMGhkSP8HOlV",
    "outputId": "fb57df5c-c70d-48bf-9614-9cb68eac9355"
   },
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zx3XE1qp6cDP"
   },
   "outputs": [],
   "source": [
    "# Load the AdamW optimizer\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 5e-5, # args.learning_rate \n",
    "                  eps = 1e-8 # args.adam_epsilon \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hrVsjL46doA"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs \n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BY639ZUcIpiI"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from scipy.special import expit\n",
    "\n",
    "\n",
    "m = nn.Sigmoid()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def compute_loss(pred,target):\n",
    "\n",
    "\n",
    "        sum_mat = torch.sum(target, axis=2)\n",
    "        flat_pred = pred[sum_mat > 0][:] \n",
    "        flat_target  = target[ sum_mat > 0][:]\n",
    "        # print(criterion(flat_pred, flat_target))\n",
    "        return criterion(m(flat_pred), flat_target)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.array([ 0, 0, 0.1])\n",
    "g = expit(z)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-hCgMRJ6lEs",
    "outputId": "8faf921a-f5ce-4034-b909-32e911b3e858"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "loss_values = []\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    \n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "       \n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        model.zero_grad()\n",
    "     \n",
    "        # with torch.no_grad():\n",
    "        outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "        loss = compute_loss(outputs.logits, b_labels)\n",
    "        loss.requires_grad_()\n",
    "        # print(loss.item())\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "filename = 'model1.h5'\n",
    "joblib.dump(model, filename)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kZYUE2OIORBX",
    "outputId": "3fd4eef3-69ed-43fd-c7ca-a7028368b914"
   },
   "outputs": [],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TrA3ybPz6p53"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# % matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# Use plot styling from seaborn.\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "# Increase the plot size and font size.\n",
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "# Plot the learning curve.\n",
    "plt.plot(loss_values, 'b-o')\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_vecs():\n",
    "    f = open('data/test.json')\n",
    "    test_data = json.load(f)\n",
    "    f.close()\n",
    "    a = [d[\"sent\"] for d in test_data]\n",
    "    set_ = set()\n",
    "    for idx,s in enumerate(a):\n",
    "        for t in s:\n",
    "            if len(t)<1:\n",
    "                set_.add(idx)\n",
    "    test_data = [test_data[i] for i in range(len(test_data)) if i not in set_]\n",
    "    df = pd.DataFrame(test_data)\n",
    "    df[\"sent\"] = df[\"sent\"].map( lambda x: clean_text(x))\n",
    "    df[\"features\"] = df[\"sent\"].map(lambda x: get_sent_features(x))\n",
    "    df[\"labels\"] = df[\"tags\"].map(lambda x: label2id(x))\n",
    "    sentences = list(df[\"sent\"])\n",
    "    labels = list(df[\"labels\"])\n",
    "#     from warnings import simplefilter\n",
    "    simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sent in tqdm(sentences):\n",
    "\n",
    "        sent_str = ' '.join(sent)\n",
    "    #     print(len(sent))\n",
    "    #     print(sent_str)\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent_str,                 \n",
    "                            add_special_tokens = False,\n",
    "                            truncation = True,\n",
    "                            max_length = 105,           \n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   \n",
    "                            return_tensors = 'pt',     \n",
    "                       )\n",
    "\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'][0])\n",
    "\n",
    "        # And its attention mask\n",
    "        attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "    new_labels = []\n",
    "\n",
    "    # The special label ID we'll give to \"extra\" tokens.\n",
    "    to_remove_idx = []\n",
    "    null_label_id =  np.zeros(2*NUM_TAGS+1, np.int32) #-100\n",
    "    idx = 0\n",
    "    for (tokens, masks, orig_labels) in zip(input_ids, attention_masks, labels):\n",
    "\n",
    "        padded_labels = []\n",
    "        ty = 0\n",
    "        orig_labels_i = 0 \n",
    "        # print(tokens, masks, orig_labels)\n",
    "\n",
    "        for token_id,mask_id in zip(tokens,masks):\n",
    "          token_id = token_id.numpy().item()\n",
    "\n",
    "          if mask_id.numpy().item() == 0:\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "\n",
    "          elif (token_id == tokenizer.pad_token_id) or \\\n",
    "              (token_id == tokenizer.cls_token_id) or \\\n",
    "              (token_id == tokenizer.sep_token_id):\n",
    "\n",
    "              padded_labels.append(null_label_id)\n",
    "\n",
    "          elif tokenizer.ids_to_tokens[token_id][0:2] == '##':\n",
    "\n",
    "              padded_labels.append(null_label_id)\n",
    "\n",
    "          else:\n",
    "            # print(tokenizer.ids_to_tokens[token_id], orig_labels_i, len(orig_labels))\n",
    "            if orig_labels_i >= len(orig_labels):\n",
    "              ty+=1\n",
    "              break\n",
    "            else:\n",
    "\n",
    "              padded_labels.append(to_bool_vec(orig_labels[orig_labels_i]))\n",
    "            orig_labels_i += 1\n",
    "\n",
    "        # assert(len(sen) == len(padded_labels))    \n",
    "        if ty == 0:\n",
    "          new_labels.append(padded_labels)\n",
    "        else:\n",
    "          to_remove_idx.append(idx)\n",
    "        idx+=1\n",
    "    filtered_attention_masks = [attention_masks[idx] for idx in range(len(attention_masks)) if idx not in to_remove_idx]\n",
    "    filtered_input_ids = [input_ids[idx] for idx in range(len(input_ids)) if idx not in to_remove_idx]\n",
    "    pt_input_ids = torch.stack(filtered_input_ids, dim=0)\n",
    "\n",
    "    pt_attention_masks = torch.stack(filtered_attention_masks, dim=0)\n",
    "\n",
    "    pt_labels = torch.tensor(new_labels, dtype=torch.float32)\n",
    "    return pt_input_ids, pt_attention_masks, pt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_input_ids.size(), pt_attention_masks.size(), pt_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import  SequentialSampler\n",
    "\n",
    "pt_input_ids, pt_attention_masks, pt_labels = get_test_vecs()\n",
    "batch_size = 256\n",
    "prediction_data = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(pt_input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# First, combine the results across the batches.\n",
    "all_predictions = np.concatenate(predictions, axis=0)\n",
    "all_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "print(\"After flattening the batches, the predictions have shape:\")\n",
    "print(\"    \", all_predictions.shape)\n",
    "\n",
    "# Next, let's remove the third dimension (axis 2), which has the scores\n",
    "# for all 18 labels. \n",
    "\n",
    "# For each token, pick the label with the highest score.\n",
    "# predicted_label_ids = np.argmax(all_predictions, axis=2)\n",
    "\n",
    "# print(\"\\nAfter choosing the highest scoring label for each token:\")\n",
    "# print(\"    \", predicted_label_ids.shape) \n",
    "\n",
    "\n",
    "# Eliminate axis 0, which corresponds to the sentences.\n",
    "predicted_label_ids = np.concatenate(all_predictions, axis=0)\n",
    "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "sum_mat = np.sum(all_true_labels, axis=1)\n",
    "# [sum_mat >0.2])\n",
    "predicted_label_ids = predicted_label_ids [sum_mat > 0.1][:]\n",
    "all_true_labels = all_true_labels [sum_mat > 0.1][:]\n",
    "\n",
    "print(\"\\nAfter flattening the sentences, we have predictions:\")\n",
    "print(\"    \", predicted_label_ids.shape)\n",
    "print(\"and ground truth:\")\n",
    "print(\"    \", all_true_labels.shape)\n",
    "# print(sum_mat.shape)\n",
    "predicted_label_ids = np.concatenate(predicted_label_ids, axis=0)\n",
    "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "\n",
    "\n",
    "print(\"\\nAfter flattening the sentences, we have predictions:\")\n",
    "print(\"    \", predicted_label_ids.shape)\n",
    "print(\"and ground truth:\")\n",
    "print(\"    \", all_true_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_true_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(all_true_labels, predicted_label_ids, average='micro') \n",
    "\n",
    "print (\"F1 score: {:.2%}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZKvGH25SU23"
   },
   "outputs": [],
   "source": [
    "# import transformers\n",
    "# from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification\n",
    "# import torch\n",
    "# from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "# from transformers import BertConfig, BertModel\n",
    "# class seq2SeqBERT(torch.nn.Module):\n",
    "# \tdef __init__(self):\n",
    "# \t\tsuper(seq2SeqBERT, self).__init__()\n",
    "# \t\tconfiguration = BertConfig()\n",
    "# \t\tself.bert = BertModel(configuration)\n",
    "# \t\tself.classifier = torch.nn.Linear(768, 5)\n",
    "# \t\tself.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# \tdef forward(self, input_ids, attention_mask, labels = None):\n",
    "# \t\tembeddings = self.bert(input_ids = input_ids, attention_mask = attention_mask)\n",
    "# \t\tlogits = self.classifier(embeddings['last_hidden_state'])\n",
    "# \t\tloss_ = None\n",
    "# \t\tflat_outputs = logits[labels!=-100]\n",
    "# \t\tflat_labels  = labels[ labels!=-100]\n",
    "# \t\tif labels is not None:\n",
    "# \t\t\tloss_ = self.criterion(flat_outputs, flat_labels)\n",
    "# \t\treturn SequenceClassifierOutput(loss = loss_, logits = logits, attentions=embeddings"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01b14a65e71d426091b7c30555780b6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02d44ec9f6c84507bbbfd53b506ace62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f680bcfe2424abbb433b4f4f7c200bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5cd01d46aceb47fa85c71a36d8ffd9e6",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_87596d96a965425a83870c1e0ff759ae",
      "value": 570
     }
    },
    "1c9f7c3885d84bc0adcb0fe5e1f6fa09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21e8758e69b641759a450407231f8db5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "237c7cfb3d444ae7984bbd8ea533106f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54903b3d0a9246ffb22a2a98d0efb44c",
      "placeholder": "​",
      "style": "IPY_MODEL_6700cf33f9f54ac98ec1f8372a7864d3",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "31ea48f16f46494ca5873eecbc164a71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3edaa70eaede4b6fb0480e3ca79b39fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "400ee20667f94c7aac1574be3a1a9e5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43f47bad9a884045af5adee529af47ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02d44ec9f6c84507bbbfd53b506ace62",
      "placeholder": "​",
      "style": "IPY_MODEL_a3ef234e82dc43eda9be0529defef357",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "45aaad9a51434af588ea9b8d8d68bb05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ee46924befa45ed9d5478edde21495b",
      "placeholder": "​",
      "style": "IPY_MODEL_75b50857bb224e7cb8b97d4526adf383",
      "value": " 232k/232k [00:00&lt;00:00, 910kB/s]"
     }
    },
    "4ee46924befa45ed9d5478edde21495b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54659ba43744406ca9d84e0a8436e4a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f38d803a38eb4aeba24d4934a293b683",
      "placeholder": "​",
      "style": "IPY_MODEL_ebaf2717cd204b24a53854b272f8ee4b",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "54903b3d0a9246ffb22a2a98d0efb44c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5608b9e6a55142628a844b0766d3553f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "575152d3234a481e9d1497562517db92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a1d1c7a34074d4b9ac1002ce35eaed2",
      "placeholder": "​",
      "style": "IPY_MODEL_1c9f7c3885d84bc0adcb0fe5e1f6fa09",
      "value": " 28.0/28.0 [00:00&lt;00:00, 906B/s]"
     }
    },
    "5a1d1c7a34074d4b9ac1002ce35eaed2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cd01d46aceb47fa85c71a36d8ffd9e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6700cf33f9f54ac98ec1f8372a7864d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75b50857bb224e7cb8b97d4526adf383": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87596d96a965425a83870c1e0ff759ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a33c6625ca5c40ed94757906d8336113": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a3ef234e82dc43eda9be0529defef357": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b233bf4bab374f2896ce104d99f13827": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_237c7cfb3d444ae7984bbd8ea533106f",
       "IPY_MODEL_fdc50b855ddb494b9765751101814c40",
       "IPY_MODEL_45aaad9a51434af588ea9b8d8d68bb05"
      ],
      "layout": "IPY_MODEL_400ee20667f94c7aac1574be3a1a9e5e"
     }
    },
    "bcc6be30fffb45399b37a7f6692b08ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3edaa70eaede4b6fb0480e3ca79b39fd",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff7ec28470d24e2db9ba2da9212940d6",
      "value": 28
     }
    },
    "c447f434facb4e7dad6d68cdb7d3c9ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43f47bad9a884045af5adee529af47ac",
       "IPY_MODEL_0f680bcfe2424abbb433b4f4f7c200bf",
       "IPY_MODEL_ecee498b70ac4f74ae130814f34681d2"
      ],
      "layout": "IPY_MODEL_31ea48f16f46494ca5873eecbc164a71"
     }
    },
    "e02aec09e217439e8d4bd886dbcb277f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e935a869ed12455fb576203015cec180": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54659ba43744406ca9d84e0a8436e4a6",
       "IPY_MODEL_bcc6be30fffb45399b37a7f6692b08ee",
       "IPY_MODEL_575152d3234a481e9d1497562517db92"
      ],
      "layout": "IPY_MODEL_01b14a65e71d426091b7c30555780b6b"
     }
    },
    "ebaf2717cd204b24a53854b272f8ee4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecee498b70ac4f74ae130814f34681d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5608b9e6a55142628a844b0766d3553f",
      "placeholder": "​",
      "style": "IPY_MODEL_21e8758e69b641759a450407231f8db5",
      "value": " 570/570 [00:00&lt;00:00, 31.7kB/s]"
     }
    },
    "f38d803a38eb4aeba24d4934a293b683": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdc50b855ddb494b9765751101814c40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e02aec09e217439e8d4bd886dbcb277f",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a33c6625ca5c40ed94757906d8336113",
      "value": 231508
     }
    },
    "ff7ec28470d24e2db9ba2da9212940d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
