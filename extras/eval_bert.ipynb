{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQ9r110W16eF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "import wget\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGmxlfMj2O-h",
    "outputId": "523754a0-8e91-4b4e-a77b-ea4831e776f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "Available: NVIDIA A100-SXM4-80GB\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print( torch.cuda.device_count())\n",
    "    print('Available:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JF22X4Ak2Re6",
    "outputId": "d20f0e25-80d3-4389-e7e3-20fea38b7ef3"
   },
   "outputs": [],
   "source": [
    "!pip install wget\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5GCuBeo2UaV"
   },
   "outputs": [],
   "source": [
    "# url_data = ''\n",
    "# wget.download(url_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "55ebZib03nxy"
   },
   "outputs": [],
   "source": [
    "def word_shape_features(word):\n",
    "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
    "                     word.isdigit(),  word.isalpha(),word.isalnum(), word.isnumeric()])\n",
    "\n",
    "def get_word_features(word):\n",
    "    return word_shape_features(word)\n",
    "\n",
    "def get_sent_features(sent):\n",
    "    ret = []\n",
    "    for word in sent:\n",
    "        ret.append(get_word_features(word))\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yWfSqa2v3w7r"
   },
   "outputs": [],
   "source": [
    "TAGS =  pickle.load(open( \"tags.pickle\", \"rb\" ))\n",
    "TAGS.remove(\"O\") \n",
    "NUM_TAGS = len(TAGS)\n",
    "\n",
    "tag2id = {}\n",
    "for id,label in enumerate(TAGS):\n",
    "    tag2id[label] = id \n",
    "\n",
    "def label2id(labels):\n",
    "    ret = []\n",
    "    prev_label = \"\"\n",
    "    for label in labels:\n",
    "        if label == \"O\":\n",
    "            ret.append([2*NUM_TAGS])\n",
    "        elif label == prev_label:\n",
    "            l =[tag2id[t]+ NUM_TAGS for t in label]\n",
    "            ret.append(l)\n",
    "        else:\n",
    "            l =[tag2id[t] for t in label]\n",
    "            ret.append(l)\n",
    "        prev_label = label\n",
    "    return ret "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tixMcZNi3uOb"
   },
   "outputs": [],
   "source": [
    "def get_label(label_id):\n",
    "    if label_id == (2*NUM_TAGS):\n",
    "        return \"O\"\n",
    "    elif label_id >= NUM_TAGS:\n",
    "        return [TAGS[label_id-NUM_TAGS]]\n",
    "    else:\n",
    "        return TAGS[label_id]\n",
    "\n",
    "def id2label(labels):\n",
    "    ret = []\n",
    "    for label in labels:\n",
    "        l = [get_label(x) for x in label]\n",
    "        if len(l) == 1 and l[0] == \"O\":\n",
    "            l = \"O\"\n",
    "        ret.append(l)\n",
    "    return ret \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "V5ECkv6eL9RI"
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "def clean_text(sent):\n",
    "    '''\n",
    "    This is text cleaning function\n",
    "    '''\n",
    "    ret_sent= []\n",
    "    for txt in sent:\n",
    "#       if len(txt) < 1:\n",
    "# #         print(\"HI\",txt, sent)\n",
    "#         return -1\n",
    "      fil_txt = re.sub('[^A-Za-z0-9]+', '', str(txt))\n",
    "      if len(fil_txt) == 0:\n",
    "        fil_txt  = txt [0]\n",
    "      ret_sent.append(fil_txt)\n",
    "    assert(len(ret_sent) == len(sent))\n",
    "    return ret_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lFbrUUGL6gJ",
    "outputId": "446ccad2-a59a-47cb-b88d-ca39ab9b43be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABC', '-']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text([\"---ABC\", \"--\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141,
     "referenced_widgets": [
      "b233bf4bab374f2896ce104d99f13827",
      "237c7cfb3d444ae7984bbd8ea533106f",
      "fdc50b855ddb494b9765751101814c40",
      "45aaad9a51434af588ea9b8d8d68bb05",
      "400ee20667f94c7aac1574be3a1a9e5e",
      "54903b3d0a9246ffb22a2a98d0efb44c",
      "6700cf33f9f54ac98ec1f8372a7864d3",
      "e02aec09e217439e8d4bd886dbcb277f",
      "a33c6625ca5c40ed94757906d8336113",
      "4ee46924befa45ed9d5478edde21495b",
      "75b50857bb224e7cb8b97d4526adf383",
      "e935a869ed12455fb576203015cec180",
      "54659ba43744406ca9d84e0a8436e4a6",
      "bcc6be30fffb45399b37a7f6692b08ee",
      "575152d3234a481e9d1497562517db92",
      "01b14a65e71d426091b7c30555780b6b",
      "f38d803a38eb4aeba24d4934a293b683",
      "ebaf2717cd204b24a53854b272f8ee4b",
      "3edaa70eaede4b6fb0480e3ca79b39fd",
      "ff7ec28470d24e2db9ba2da9212940d6",
      "5a1d1c7a34074d4b9ac1002ce35eaed2",
      "1c9f7c3885d84bc0adcb0fe5e1f6fa09",
      "c447f434facb4e7dad6d68cdb7d3c9ed",
      "43f47bad9a884045af5adee529af47ac",
      "0f680bcfe2424abbb433b4f4f7c200bf",
      "ecee498b70ac4f74ae130814f34681d2",
      "31ea48f16f46494ca5873eecbc164a71",
      "02d44ec9f6c84507bbbfd53b506ace62",
      "a3ef234e82dc43eda9be0529defef357",
      "5cd01d46aceb47fa85c71a36d8ffd9e6",
      "87596d96a965425a83870c1e0ff759ae",
      "5608b9e6a55142628a844b0766d3553f",
      "21e8758e69b641759a450407231f8db5"
     ]
    },
    "id": "MSVMBUOd3ZFp",
    "outputId": "9a49eead-8bc5-4b3d-b08b-ad4aac326e1d"
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import numpy as np\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, random_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "eoX1GeW4TXh8"
   },
   "outputs": [],
   "source": [
    "def to_bool_vec(y_id):\n",
    "    y_bool = np.zeros(2*NUM_TAGS+1, np.int32)\n",
    "    num_labels = len(y_id)\n",
    "    for id in y_id:\n",
    "        # for l in label:\n",
    "          y_bool[id] = 1\n",
    "    return y_bool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJax2Fuu6WuP",
    "outputId": "bfd86522-17e4-4107-c0d4-7b85d678db80"
   },
   "outputs": [],
   "source": [
    "from transformers import BertForTokenClassification, AdamW, BertConfig\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "model = joblib.load('model_0.h5')\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "id": "BY639ZUcIpiI"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from scipy.special import expit\n",
    "import random\n",
    "import joblib\n",
    "from warnings import simplefilter\n",
    "from tqdm import tqdm\n",
    "\n",
    "m = nn.Sigmoid()\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def compute_loss(pred,target):\n",
    "        sum_mat = torch.sum(target, axis=2)\n",
    "        flat_pred = pred[sum_mat > 0][:] \n",
    "        flat_target  = target[ sum_mat > 0][:]\n",
    "        # print(criterion(flat_pred, flat_target))\n",
    "        return criterion(m(flat_pred), flat_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_vecs():\n",
    "#     f = open('data/test.json')\n",
    "    f = open('data/dev.json')\n",
    "\n",
    "    test_data = json.load(f)\n",
    "    f.close()\n",
    "    a = [d[\"sent\"] for d in test_data]\n",
    "    set_ = set()\n",
    "    for idx,s in enumerate(a):\n",
    "        for t in s:\n",
    "            if len(t)<1:\n",
    "                set_.add(idx)\n",
    "    test_data = [test_data[i] for i in range(len(test_data)) if i not in set_]\n",
    "    df = pd.DataFrame(test_data)\n",
    "    df[\"sent\"] = df[\"sent\"].map( lambda x: clean_text(x))\n",
    "    df[\"features\"] = df[\"sent\"].map(lambda x: get_sent_features(x))\n",
    "    df[\"labels\"] = df[\"tags\"].map(lambda x: label2id(x))\n",
    "    sentences = list(df[\"sent\"])\n",
    "    labels = list(df[\"labels\"])\n",
    "#     from warnings import simplefilter\n",
    "    simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sent in tqdm(sentences):\n",
    "\n",
    "        sent_str = ' '.join(sent)\n",
    "    #     print(len(sent))\n",
    "    #     print(sent_str)\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent_str,                 \n",
    "                            add_special_tokens = False,\n",
    "                            truncation = True,\n",
    "                            max_length = 105,           \n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,   \n",
    "                            return_tensors = 'pt',     \n",
    "                       )\n",
    "\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'][0])\n",
    "\n",
    "        # And its attention mask\n",
    "        attention_masks.append(encoded_dict['attention_mask'][0])\n",
    "    new_labels = []\n",
    "\n",
    "    # The special label ID we'll give to \"extra\" tokens.\n",
    "    to_remove_idx = []\n",
    "    null_label_id =  np.zeros(2*NUM_TAGS+1, np.int32) #-100\n",
    "    idx = 0\n",
    "    for (tokens, masks, orig_labels) in zip(input_ids, attention_masks, labels):\n",
    "\n",
    "        padded_labels = []\n",
    "        ty = 0\n",
    "        orig_labels_i = 0 \n",
    "        # print(tokens, masks, orig_labels)\n",
    "\n",
    "        for token_id,mask_id in zip(tokens,masks):\n",
    "          token_id = token_id.numpy().item()\n",
    "\n",
    "          if mask_id.numpy().item() == 0:\n",
    "            padded_labels.append(null_label_id)\n",
    "\n",
    "\n",
    "          elif (token_id == tokenizer.pad_token_id) or \\\n",
    "              (token_id == tokenizer.cls_token_id) or \\\n",
    "              (token_id == tokenizer.sep_token_id):\n",
    "\n",
    "              padded_labels.append(null_label_id)\n",
    "\n",
    "          elif tokenizer.ids_to_tokens[token_id][0:2] == '##':\n",
    "\n",
    "              padded_labels.append(null_label_id)\n",
    "\n",
    "          else:\n",
    "            # print(tokenizer.ids_to_tokens[token_id], orig_labels_i, len(orig_labels))\n",
    "            if orig_labels_i >= len(orig_labels):\n",
    "              ty+=1\n",
    "              break\n",
    "            else:\n",
    "\n",
    "              padded_labels.append(to_bool_vec(orig_labels[orig_labels_i]))\n",
    "            orig_labels_i += 1\n",
    "\n",
    "        # assert(len(sen) == len(padded_labels))    \n",
    "        if ty == 0:\n",
    "          new_labels.append(padded_labels)\n",
    "        else:\n",
    "          to_remove_idx.append(idx)\n",
    "        idx+=1\n",
    "    filtered_attention_masks = [attention_masks[idx] for idx in range(len(attention_masks)) if idx not in to_remove_idx]\n",
    "    filtered_input_ids = [input_ids[idx] for idx in range(len(input_ids)) if idx not in to_remove_idx]\n",
    "    pt_input_ids = torch.stack(filtered_input_ids, dim=0)\n",
    "\n",
    "    pt_attention_masks = torch.stack(filtered_attention_masks, dim=0)\n",
    "\n",
    "    pt_labels = torch.tensor(new_labels, dtype=torch.float32)\n",
    "    return pt_input_ids, pt_attention_masks, pt_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 278/278 [00:00<00:00, 1620.21it/s]\n"
     ]
    }
   ],
   "source": [
    "pt_input_ids, pt_attention_masks, pt_labels = get_test_vecs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([278, 105]), torch.Size([278, 105]), torch.Size([278, 105, 227]))"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_input_ids.size(), pt_attention_masks.size(), pt_labels.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 278/278 [00:00<00:00, 1614.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import  SequentialSampler\n",
    "\n",
    "pt_input_ids, pt_attention_masks, pt_labels = get_test_vecs()\n",
    "batch_size = 256\n",
    "prediction_data = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 278 test sentences...\n",
      "    DONE.\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(pt_input_ids)))\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "  logits = m(logits)\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = np.concatenate(predictions, axis=0)\n",
    "all_true_labels = np.concatenate(true_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((278, 105, 227), (278, 105, 227))"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions.shape, all_true_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_mat = np.sum(all_true_labels, axis=2)\n",
    "# [sum_mat >0.2])\n",
    "predicted_label_ids = all_predictions [sum_mat > 0.1][:]\n",
    "all_true_labels = all_true_labels [sum_mat > 0.1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_mat = np.sum(all_true_labels, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_label_ids = all_predictions [sum_mat > 0.1][:]\n",
    "# all_true_labels = all_true_labels [sum_mat > 0.1][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = [i for i in range(all_true_labels.shape[0])if np.round(all_true_labels[i][226]) != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6944, 227), (6944, 227))"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_label_ids.shape, all_true_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.65\n",
    "pred = []\n",
    "true = []\n",
    "for p in predicted_label_ids:\n",
    "    rt = [i for (i,x) in enumerate(p) if x >t]\n",
    "    pred.append(rt)\n",
    "for p in all_true_labels:\n",
    "    rt = [i for (i,x) in enumerate(p) if round(x)  == 1]\n",
    "    true.append(rt)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.8716565860215054, 0.8762480798771122, 0.8739463023527214),\n",
       " (0.8965367965367965, 0.8425549227013832, 0.8687080536912751))"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loose_macro(true,pred), loose_micro(true,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a,b in zip(pred, true):\n",
    "#     print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(p, r):\n",
    "            if r == 0.:\n",
    "                return 0.\n",
    "            return 2 * p * r / float( p + r )\n",
    "def loose_macro(true, pred):\n",
    "    num_entities = len(true)\n",
    "    p = 0.\n",
    "    r = 0.\n",
    "    for true_labels, predicted_labels in zip(true, pred):\n",
    "        if len(predicted_labels) > 0:\n",
    "            p += len(set(predicted_labels).intersection(set(true_labels))) / float(len(predicted_labels))\n",
    "        if len(true_labels):\n",
    "            r += len(set(predicted_labels).intersection(set(true_labels))) / float(len(true_labels))\n",
    "    precision = p / num_entities\n",
    "    recall = r / num_entities\n",
    "    return precision, recall, f1( precision, recall)\n",
    "def loose_micro(true, pred):\n",
    "    num_predicted_labels = 0.\n",
    "    num_true_labels = 0.\n",
    "    num_correct_labels = 0.\n",
    "    for true_labels, predicted_labels in zip(true, pred):\n",
    "        num_predicted_labels += len(predicted_labels)\n",
    "        num_true_labels += len(true_labels)\n",
    "        num_correct_labels += len(set(predicted_labels).intersection(set(true_labels))) \n",
    "    if num_predicted_labels > 0:\n",
    "        precision = num_correct_labels / num_predicted_labels\n",
    "    else:\n",
    "        precision = 0.\n",
    "    recall = num_correct_labels / num_true_labels\n",
    "    return precision, recall, f1( precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_ids = predicted_label_ids[xt]\n",
    "all_true_labels = all_true_labels[xt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = []\n",
    "yt = []\n",
    "for i1,at in enumerate(all_true_labels):\n",
    "    for i,x in enumerate(at):\n",
    "        if np.round(x) == 1:\n",
    "            rt.append(predicted_label_ids[i1][i])\n",
    "        else :\n",
    "            yt.append(predicted_label_ids[i1][i])\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(p, r):\n",
    "    if r == 0.:\n",
    "        return 0.\n",
    "    return 2 * p * r / float( p + r )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:  0.4797979797979798\n",
      "precision:  0.36004331348132107\n",
      "f1:  0.4113826167646149\n",
      "accuracy:  99.12308996737508\n"
     ]
    }
   ],
   "source": [
    "t = 0.23\n",
    "TP = len([x for x in rt if x >= t]) \n",
    "TN = len([x for x in yt if x < t]) \n",
    "FP = len([x for x in yt if x >= t])\n",
    "FN = len([x for x in rt if x < t])\n",
    "recall = TP/(TP + FN)\n",
    "precision =  TP/(TP + FP)\n",
    "print(\"recall: \", TP/(TP + FN))\n",
    "print(\"precision: \", TP/(TP + FP))\n",
    "print(\"f1: \", f1(precision, recall))\n",
    "print(\"accuracy: \", (TP+ TN)*100/(TP + FP + FN + TN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619 214542 1084 767\n"
     ]
    }
   ],
   "source": [
    "print(\"recall: \", TP/(TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision:  0.3634762184380505\n"
     ]
    }
   ],
   "source": [
    "print(\"precision: \", TP/(TP + FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall:  0.4466089466089466\n"
     ]
    }
   ],
   "source": [
    "print(\"recall: \", TP/(TP + FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.7847492304573019\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy: \", (TP+ FP)*100/(TP + FP + FN + TN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n",
      "134\n"
     ]
    }
   ],
   "source": [
    "for i,z in enumerate(rt):\n",
    "    if z == True:\n",
    "        print(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(p, r):\n",
    "            if r == 0.:\n",
    "                return 0.\n",
    "            return 2 * p * r / float( p + r )\n",
    "        def loose_macro(true, pred):\n",
    "            num_entities = len(true)\n",
    "            p = 0.\n",
    "            r = 0.\n",
    "            for true_labels, predicted_labels in zip(true, pred):\n",
    "                if len(predicted_labels) > 0:\n",
    "                    p += len(set(predicted_labels).intersection(set(true_labels))) / float(len(predicted_labels))\n",
    "                if len(true_labels):\n",
    "                    r += len(set(predicted_labels).intersection(set(true_labels))) / float(len(true_labels))\n",
    "            precision = p / num_entities\n",
    "            recall = r / num_entities\n",
    "            return precision, recall, f1( precision, recall)\n",
    "        def loose_micro(true, pred):\n",
    "            num_predicted_labels = 0.\n",
    "            num_true_labels = 0.\n",
    "            num_correct_labels = 0.\n",
    "            for true_labels, predicted_labels in zip(true, pred):\n",
    "                num_predicted_labels += len(predicted_labels)\n",
    "                num_true_labels += len(true_labels)\n",
    "                num_correct_labels += len(set(predicted_labels).intersection(set(true_labels))) \n",
    "            if num_predicted_labels > 0:\n",
    "                precision = num_correct_labels / num_predicted_labels\n",
    "            else:\n",
    "                precision = 0.\n",
    "            recall = num_correct_labels / num_true_labels\n",
    "            return precision, recall, f1( precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(p, r):\n",
    "    if r == 0.:\n",
    "        return 0.\n",
    "    return 2 * p * r / float( p + r )\n",
    "def loose_macro(true, pred):\n",
    "    num_entities = len(true)\n",
    "    p = 0.\n",
    "    r = 0.\n",
    "    for true_labels, predicted_labels in zip(true, pred):\n",
    "        if len(predicted_labels) > 0:\n",
    "            p += len(set(predicted_labels).intersection(set(true_labels))) / float(len(predicted_labels))\n",
    "        if len(true_labels):\n",
    "            r += len(set(predicted_labels).intersection(set(true_labels))) / float(len(true_labels))\n",
    "    precision = p / num_entities\n",
    "    recall = r / num_entities\n",
    "    return precision, recall, f1( precision, recall)\n",
    "def loose_micro(true, pred):\n",
    "    num_predicted_labels = 0.\n",
    "    num_true_labels = 0.\n",
    "    num_correct_labels = 0.\n",
    "    for true_labels, predicted_labels in zip(true, pred):\n",
    "        num_predicted_labels += len(predicted_labels)\n",
    "        num_true_labels += len(true_labels)\n",
    "        num_correct_labels += len(set(predicted_labels).intersection(set(true_labels))) \n",
    "    if num_predicted_labels > 0:\n",
    "        precision = num_correct_labels / num_predicted_labels\n",
    "    else:\n",
    "        precision = 0.\n",
    "    recall = num_correct_labels / num_true_labels\n",
    "    return precision, recall, f1( precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# First, combine the results across the batches.\n",
    "all_predictions = np.concatenate(predictions, axis=0)\n",
    "all_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "print(\"After flattening the batches, the predictions have shape:\")\n",
    "print(\"    \", all_predictions.shape)\n",
    "\n",
    "# Next, let's remove the third dimension (axis 2), which has the scores\n",
    "# for all 18 labels. \n",
    "\n",
    "# For each token, pick the label with the highest score.\n",
    "# predicted_label_ids = np.argmax(all_predictions, axis=2)\n",
    "\n",
    "# print(\"\\nAfter choosing the highest scoring label for each token:\")\n",
    "# print(\"    \", predicted_label_ids.shape) \n",
    "\n",
    "\n",
    "# Eliminate axis 0, which corresponds to the sentences.\n",
    "predicted_label_ids = np.concatenate(all_predictions, axis=0)\n",
    "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "sum_mat = np.sum(all_true_labels, axis=1)\n",
    "# [sum_mat >0.2])\n",
    "predicted_label_ids = predicted_label_ids [sum_mat > 0.1][:]\n",
    "all_true_labels = all_true_labels [sum_mat > 0.1][:]\n",
    "\n",
    "print(\"\\nAfter flattening the sentences, we have predictions:\")\n",
    "print(\"    \", predicted_label_ids.shape)\n",
    "print(\"and ground truth:\")\n",
    "print(\"    \", all_true_labels.shape)\n",
    "# print(sum_mat.shape)\n",
    "predicted_label_ids = np.concatenate(predicted_label_ids, axis=0)\n",
    "all_true_labels = np.concatenate(all_true_labels, axis=0)\n",
    "\n",
    "\n",
    "print(\"\\nAfter flattening the sentences, we have predictions:\")\n",
    "print(\"    \", predicted_label_ids.shape)\n",
    "print(\"and ground truth:\")\n",
    "print(\"    \", all_true_labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_true_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.1'"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_label_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [97]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpredicted_label_ids\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_label_ids' is not defined"
     ]
    }
   ],
   "source": [
    "predicted_label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(all_true_labels, predicted_label_ids, average='micro') \n",
    "\n",
    "print (\"F1 score: {:.2%}\".format(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 9956/9956 [00:07<00:00, 1406.99it/s]\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "d = {}\n",
    "pt_input_ids, pt_attention_masks, pt_labels = get_test_vecs()\n",
    "prediction_data = TensorDataset(pt_input_ids, pt_attention_masks, pt_labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "for m1 in tqdm(range(0,8)):\n",
    "    d[m1] = {}\n",
    "    name = 'model_{}.h5'.format(m1)\n",
    "    model = joblib.load(name)\n",
    "    model.cuda()\n",
    "    batch_size = 512\n",
    "#     print('Predicting labels for {:,} test sentences...'.format(len(pt_input_ids)))\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    predictions , true_labels = [], []\n",
    "\n",
    "    # Predict \n",
    "    for batch in prediction_dataloader:\n",
    "      # Add batch to GPU\n",
    "      batch = tuple(t.to(device) for t in batch)\n",
    "\n",
    "      # Unpack the inputs from our dataloader\n",
    "      b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "      # Telling the model not to compute or store gradients, saving memory and \n",
    "\n",
    "      with torch.no_grad():\n",
    "          # Forward pass, calculate logit predictions\n",
    "          outputs = model(b_input_ids, token_type_ids=None, \n",
    "                          attention_mask=b_input_mask)\n",
    "\n",
    "      logits = outputs[0]\n",
    "      logits = m(logits)\n",
    "\n",
    "      # Move logits and labels to CPU\n",
    "      logits = logits.detach().cpu().numpy()\n",
    "      label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "      # Store predictions and true labels\n",
    "      predictions.append(logits)\n",
    "      true_labels.append(label_ids)\n",
    "\n",
    "#     print('    DONE.')\n",
    "    all_predictions = np.concatenate(predictions, axis=0)\n",
    "    all_true_labels = np.concatenate(true_labels, axis=0)\n",
    "    sum_mat = np.sum(all_true_labels, axis=2)\n",
    "    # [sum_mat >0.2])\n",
    "    predicted_label_ids = all_predictions [sum_mat > 0.1][:]\n",
    "    all_true_labels = all_true_labels [sum_mat > 0.1][:]\n",
    "    for thresh in np.arange(0.1,9.0,0.01):\n",
    "        d[m1][str(thresh)] = {}\n",
    "        t = thresh\n",
    "        pred = []\n",
    "        true = []\n",
    "        for p in predicted_label_ids:\n",
    "            rt = [i for (i,x) in enumerate(p) if x >t]\n",
    "            pred.append(rt)\n",
    "        for p in all_true_labels:\n",
    "            rt = [i for (i,x) in enumerate(p) if round(x)  == 1]\n",
    "            true.append(rt)\n",
    "        d[m1][str(thresh)][\"macro\"] = loose_macro(true,pred)\n",
    "        d[m1][str(thresh)][\"micro\"] = loose_micro(true,pred)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZKvGH25SU23"
   },
   "outputs": [],
   "source": [
    "# import transformers\n",
    "# from transformers import BertTokenizerFast, BertConfig, BertForTokenClassification\n",
    "# import torch\n",
    "# from transformers.modeling_outputs import SequenceClassifierOutput\n",
    "# from transformers import BertConfig, BertModel\n",
    "# class seq2SeqBERT(torch.nn.Module):\n",
    "# \tdef __init__(self):\n",
    "# \t\tsuper(seq2SeqBERT, self).__init__()\n",
    "# \t\tconfiguration = BertConfig()\n",
    "# \t\tself.bert = BertModel(configuration)\n",
    "# \t\tself.classifier = torch.nn.Linear(768, 5)\n",
    "# \t\tself.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# \tdef forward(self, input_ids, attention_mask, labels = None):\n",
    "# \t\tembeddings = self.bert(input_ids = input_ids, attention_mask = attention_mask)\n",
    "# \t\tlogits = self.classifier(embeddings['last_hidden_state'])\n",
    "# \t\tloss_ = None\n",
    "# \t\tflat_outputs = logits[labels!=-100]\n",
    "# \t\tflat_labels  = labels[ labels!=-100]\n",
    "# \t\tif labels is not None:\n",
    "# \t\t\tloss_ = self.criterion(flat_outputs, flat_labels)\n",
    "# \t\treturn SequenceClassifierOutput(loss = loss_, logits = logits, attentions=embeddings"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01b14a65e71d426091b7c30555780b6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02d44ec9f6c84507bbbfd53b506ace62": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f680bcfe2424abbb433b4f4f7c200bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5cd01d46aceb47fa85c71a36d8ffd9e6",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_87596d96a965425a83870c1e0ff759ae",
      "value": 570
     }
    },
    "1c9f7c3885d84bc0adcb0fe5e1f6fa09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "21e8758e69b641759a450407231f8db5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "237c7cfb3d444ae7984bbd8ea533106f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_54903b3d0a9246ffb22a2a98d0efb44c",
      "placeholder": "​",
      "style": "IPY_MODEL_6700cf33f9f54ac98ec1f8372a7864d3",
      "value": "Downloading (…)solve/main/vocab.txt: 100%"
     }
    },
    "31ea48f16f46494ca5873eecbc164a71": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3edaa70eaede4b6fb0480e3ca79b39fd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "400ee20667f94c7aac1574be3a1a9e5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43f47bad9a884045af5adee529af47ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_02d44ec9f6c84507bbbfd53b506ace62",
      "placeholder": "​",
      "style": "IPY_MODEL_a3ef234e82dc43eda9be0529defef357",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "45aaad9a51434af588ea9b8d8d68bb05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ee46924befa45ed9d5478edde21495b",
      "placeholder": "​",
      "style": "IPY_MODEL_75b50857bb224e7cb8b97d4526adf383",
      "value": " 232k/232k [00:00&lt;00:00, 910kB/s]"
     }
    },
    "4ee46924befa45ed9d5478edde21495b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "54659ba43744406ca9d84e0a8436e4a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f38d803a38eb4aeba24d4934a293b683",
      "placeholder": "​",
      "style": "IPY_MODEL_ebaf2717cd204b24a53854b272f8ee4b",
      "value": "Downloading (…)okenizer_config.json: 100%"
     }
    },
    "54903b3d0a9246ffb22a2a98d0efb44c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5608b9e6a55142628a844b0766d3553f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "575152d3234a481e9d1497562517db92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5a1d1c7a34074d4b9ac1002ce35eaed2",
      "placeholder": "​",
      "style": "IPY_MODEL_1c9f7c3885d84bc0adcb0fe5e1f6fa09",
      "value": " 28.0/28.0 [00:00&lt;00:00, 906B/s]"
     }
    },
    "5a1d1c7a34074d4b9ac1002ce35eaed2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cd01d46aceb47fa85c71a36d8ffd9e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6700cf33f9f54ac98ec1f8372a7864d3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "75b50857bb224e7cb8b97d4526adf383": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "87596d96a965425a83870c1e0ff759ae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a33c6625ca5c40ed94757906d8336113": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a3ef234e82dc43eda9be0529defef357": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b233bf4bab374f2896ce104d99f13827": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_237c7cfb3d444ae7984bbd8ea533106f",
       "IPY_MODEL_fdc50b855ddb494b9765751101814c40",
       "IPY_MODEL_45aaad9a51434af588ea9b8d8d68bb05"
      ],
      "layout": "IPY_MODEL_400ee20667f94c7aac1574be3a1a9e5e"
     }
    },
    "bcc6be30fffb45399b37a7f6692b08ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3edaa70eaede4b6fb0480e3ca79b39fd",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ff7ec28470d24e2db9ba2da9212940d6",
      "value": 28
     }
    },
    "c447f434facb4e7dad6d68cdb7d3c9ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43f47bad9a884045af5adee529af47ac",
       "IPY_MODEL_0f680bcfe2424abbb433b4f4f7c200bf",
       "IPY_MODEL_ecee498b70ac4f74ae130814f34681d2"
      ],
      "layout": "IPY_MODEL_31ea48f16f46494ca5873eecbc164a71"
     }
    },
    "e02aec09e217439e8d4bd886dbcb277f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e935a869ed12455fb576203015cec180": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_54659ba43744406ca9d84e0a8436e4a6",
       "IPY_MODEL_bcc6be30fffb45399b37a7f6692b08ee",
       "IPY_MODEL_575152d3234a481e9d1497562517db92"
      ],
      "layout": "IPY_MODEL_01b14a65e71d426091b7c30555780b6b"
     }
    },
    "ebaf2717cd204b24a53854b272f8ee4b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ecee498b70ac4f74ae130814f34681d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5608b9e6a55142628a844b0766d3553f",
      "placeholder": "​",
      "style": "IPY_MODEL_21e8758e69b641759a450407231f8db5",
      "value": " 570/570 [00:00&lt;00:00, 31.7kB/s]"
     }
    },
    "f38d803a38eb4aeba24d4934a293b683": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fdc50b855ddb494b9765751101814c40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e02aec09e217439e8d4bd886dbcb277f",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a33c6625ca5c40ed94757906d8336113",
      "value": 231508
     }
    },
    "ff7ec28470d24e2db9ba2da9212940d6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
