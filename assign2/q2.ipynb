{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BERT-tiny model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-tiny')\n",
    "model = AutoModel.from_pretrained('bert-tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode a sentence into a matrix of BERT-tiny embeddings\n",
    "def encode_sentence(sentence):\n",
    "    input_ids = torch.tensor([tokenizer.encode(sentence)])\n",
    "    with torch.no_grad():\n",
    "        embeddings = model(input_ids)[0]\n",
    "    return embeddings.numpy()\n",
    "\n",
    "# Compute the distance between two embeddings using cosine similarity\n",
    "def cosine_similarity(x, y):\n",
    "    dot_product = np.dot(x, y)\n",
    "    norm_x = np.linalg.norm(x)\n",
    "    norm_y = np.linalg.norm(y)\n",
    "    return dot_product / (norm_x * norm_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_matrix(sentence1, sentence2):\n",
    "    embeddings1 = encode_sentence(sentence1)\n",
    "    embeddings2 = encode_sentence(sentence2)\n",
    "    cost_matrix = np.zeros((len(embeddings1), len(embeddings2)))\n",
    "    for i in range(len(embeddings1)):\n",
    "        for j in range(len(embeddings2)):\n",
    "            cost_matrix[i][j] = 1 - cosine_similarity(embeddings1[i], embeddings2[j])\n",
    "    return cost_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform DTW with a non-crossing map that can handle degenerate solutions\n",
    "def dtw(sentence1, sentence2):\n",
    "    cost_matrix = compute_cost_matrix(sentence1, sentence2)\n",
    "    n = cost_matrix.shape[0]\n",
    "    m = cost_matrix.shape[1]\n",
    "    DTW = np.zeros((n + 1, m + 1))\n",
    "    DTW[:, 0] = np.inf\n",
    "    DTW[0, :] = np.inf\n",
    "    DTW[0, 0] = 0\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            cost = cost_matrix[i - 1][j - 1]\n",
    "            DTW[i, j] = cost + min(DTW[i - 1, j], DTW[i, j - 1], DTW[i - 1, j - 1])\n",
    "            if i == j and DTW[i, j] != np.inf:\n",
    "                DTW[i, j] = min(DTW[i, j], DTW[i - 1, j - 1] + cost)\n",
    "    return DTW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(s1, s2, DTW):\n",
    "    i, j = len(s1), len(s2)\n",
    "    alignment = []\n",
    "    while i > 0 and j > 0:\n",
    "        alignment.append((i - 1, j - 1))\n",
    "        if DTW[i - 1, j] < DTW[i - 1, j - 1] and DTW[i - 1, j] < DTW[i, j - 1]:\n",
    "            i -= 1\n",
    "        elif DTW[i, j - 1] < DTW[i - 1, j - 1] and DTW[i, j - 1] < DTW[i - 1, j]:\n",
    "            j -= 1\n",
    "        else:\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "    alignment.reverse()\n",
    "    return alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    s1 = \"This is a test sentence.\"\n",
    "    s2 = \"This sentence is a test.\"\n",
    "\n",
    "    # Compute the DTW matrix and the optimal alignment\n",
    "    DTW = dtw(s1, s2)\n",
    "    alignment = align(s1.split(), s2.split(), DTW)\n",
    "\n",
    "    # Print the alignment\n",
    "    for i, j in alignment:\n",
    "        print(f\"{s1.split()[i]} <--> {s2.split()[j]}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
